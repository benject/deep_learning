{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benject/deep_learning/blob/main/logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG_M5f8FOnhd"
      },
      "source": [
        "logistic python implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "Qbg1yZ1_NxkG"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "\n",
        "  '''sigmoid 激活函数'''\n",
        "\n",
        "  return(1.0/(1.0 + np.exp(-z)))\n",
        "\n",
        "\n",
        "def loss( real_result , predict_result):\n",
        "\n",
        "  '''损失函数'''\n",
        "\n",
        "  result = -( real_result*np.log(predict_result) + (1 - real_result)*np.log(1-predict_result))\n",
        "  return result\n",
        "\n",
        "def gradient_w(input,real_result,predict_result):\n",
        "\n",
        "  '''\n",
        "  梯度下降\n",
        "  第一步 令 y = loss（a） 对损失函数的求导 dy/da 的结果是 -y/a + (1-y)/(1-a)\n",
        "  计算过程参见 https://towardsdatascience.com/logistic-regression-from-scratch-69db4f587e17\n",
        "\n",
        "  第二步 令 a = sigmoid（z） 对sigmoid函数求导 da/dz 的结果是 a(1-a)\n",
        "  计算过程参见 https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e\n",
        "\n",
        "  第三步 根据链式求导法则 dydz = dy/da * da/dz = (-y/a + (1-y)/(1-a)) * a(1-a) = -y(1-a) + a(1-y) = -y + ay + a - ay = a - y\n",
        "\n",
        "  第四步 令 z = w1x1 + w2x2 + b 对函数求w1的偏导数 dz/dw1 = x1 以此类推\n",
        "\n",
        "  那么： dy/dw1 = dz * dz/dw1 = x1 * (a - y) \n",
        "\n",
        "  可以发现 由于精妙的激活函数和损失函数的设计，预测值对参数值的梯度 就是 预测值与真值的差 再乘以输入\n",
        "  '''\n",
        "  \n",
        "  return( input *(predict_result - real_result) )\n",
        "  \n",
        "def gradient_w_v(X,Y,A):\n",
        "\n",
        "  DZ = A - Y\n",
        "  #向量化实现\n",
        "  #X.shape = (nx,m) DZ.shape = (1,m) \n",
        "  # np.dot(X,DZ.T).shape = (nx,1)\n",
        "  return (np.dot(X,DZ.T))\n",
        "\n",
        "def gradient_b(real_result,predict_result):    \n",
        "  return( predict_result - real_result )\n",
        "\n",
        "\n",
        "\n",
        "class MyNeuron:\n",
        "\n",
        "  def __init__(self,w,b):\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "    self.learning_rate = 1\n",
        "\n",
        "    self.lr_w = 0  ##ada learning rate 自适应的学习率 可以极大提高学习效率\n",
        "    self.lr_b = 0  ##ada learning rate 自适应的学习率 可以极大提高学习效率\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = np.dot(self.w,x) + b\n",
        "    return sigmoid(z)\n",
        "\n",
        "  def update_w(self,dw):\n",
        "    self.lr_w = self.lr_w + dw**2 ##ada learning rate 自适应的学习率 可以极大提高学习效率\n",
        "    self.w = self.w - self.learning_rate / np.sqrt(self.lr_w) * dw ##ada learning rate 自适应的学习率 可以极大提高学习效率\n",
        "  \n",
        "  def update_b(self,db):\n",
        "    self.lr_b = self.lr_b + db**2 ##ada learning rate 自适应的学习率 可以极大提高学习效率\n",
        "    self.b = self.b - self.learning_rate / np.sqrt(self.lr_b) * db ##ada learning rate 自适应的学习率 可以极大提高学习效率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "JTIM2CRZRGI_"
      },
      "outputs": [],
      "source": [
        "#随机初始化权重 和 偏置\n",
        "w = np.array([[0.35],[0.45]]) # w shape is :(2, 1)\n",
        "b = 1.31\n",
        "\n",
        "#实例化一个神经元\n",
        "neu = MyNeuron (w.T,b)\n",
        "\n",
        "#填充数据\n",
        "X = np.zeros((2,600))\n",
        "Y = np.zeros((600))\n",
        "\n",
        "for i in range(300):\n",
        "\n",
        "  X[0][i] = np.random.rand() * 0.1 + 1.8\n",
        "  X[1][i] = np.random.rand() * 0.001 + 0.085\n",
        "  Y[i] = 1.0\n",
        "\n",
        "for i in range(300):\n",
        "\n",
        "  X[0][300+i] = np.random.rand() * 0.1 + 1.5\n",
        "  X[1][300+i] = np.random.rand() * 0.001 + 0.045\n",
        "  Y[300+i] = 0.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "oMn2rNmWcoQr",
        "outputId": "789cc45f-1663-42da-cf67-0409be2369af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -9.12055221 218.04838796]]\n",
            "-206.1275827818089\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "a = 0 \n",
        "dw1 = 0.0 \n",
        "dw2 = 0.0\n",
        "db = 0\n",
        "j = 0\n",
        "\n",
        "'''\n",
        "#非向量化实现\n",
        "\n",
        "for e in range(10000):\n",
        "\n",
        "  for i in range(600):\n",
        "\n",
        "    a = neu.forward(X.T[i])\n",
        "    dw1 += gradient_w(X[0][i],Y[i],a)\n",
        "    dw2 += gradient_w(X[1][i],Y[i],a)\n",
        "    db += gradient_b(Y[i],a)\n",
        "    j += loss(Y[i],a)\n",
        "\n",
        "  dw1 /= 600\n",
        "  dw2 /= 600\n",
        "  db /= 600\n",
        "  j /= 600\n",
        "\n",
        "\n",
        "  \n",
        "  neu.update_w(np.array([dw1,dw2]).T)\n",
        "  neu.update_b(np.array(db))\n",
        "  plt.scatter(e,j)\n",
        "\n",
        "  print(j)\n",
        "  if(j<0.05):\n",
        "    break\n",
        "   \n",
        "'''\n",
        "#向量化实现\n",
        "\n",
        "\n",
        "j_arr = []\n",
        "\n",
        "for e in range(100000):\n",
        "  A = neu.forward(X)  #A shape is (1,m)\n",
        "  DW = gradient_w_v(X,Y,A)/600 #DW shape is (2,1)\n",
        "  db = np.sum(gradient_b(Y,A))/600\n",
        "  j = np.sum(loss(Y,A))/600\n",
        "\n",
        "  j_arr.append(j)\n",
        "  if(j<0.05):\n",
        "    break\n",
        "  \n",
        "  neu.update_w(DW.T)\n",
        "  neu.update_b(db)\n",
        "\n",
        "plt.scatter(np.arange(len(j_arr)),j_arr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(neu.w)\n",
        "print(neu.b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "8k6FywQIUwZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405c21dd-5448-4d63-9444-372a18523f94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04459128])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "\n",
        "test = X.T[400]\n",
        "neu.forward(test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6aZHBknEaIF",
        "outputId": "6927c44c-7450-4bfa-f6b5-f6e76a68cdc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96191171])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "test1  = X.T[35]\n",
        "neu.forward(test1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "logistic.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}